{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPWOpVsH6bx+Narz9NVcVa7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LonelyFriday/spacyBasic/blob/main/spacyBasic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Overview"
      ],
      "metadata": {
        "id": "0se94hWRyB18"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "*   Load an English language model.\n",
        "*   Process a given text to analyze its structure and content.\n",
        "*   Perform tokenization to break the text into tokens (words and punctuation).\n",
        "*   Apply part-of-speech (POS) tagging to each token.\n",
        "* Execute dependency parsing to understand the grammatical structure.\n",
        "* Identify named entities (like companies, locations, amounts) within the text.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vaVlgjA7xzE-"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRyuoweSJFMz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf8e200d-d385-43c0-86c3-6fb7613485f8"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER, and word vectors\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Process a text\n",
        "text = \"Apple is looking at buying U.K. startup for $1 billion\"\n",
        "doc = nlp(text)\n",
        "\n",
        "# Tokenization, POS tagging, and Dependency Parsing\n",
        "print(\"Token\\t\\tLemma\\t\\tPOS\\t\\tTag\\t\\tDep\\t\\tShape\\t\\tis_alpha\\tis_stop\")\n",
        "for token in doc:\n",
        "    print(f\"{token.text}\\t\\t{token.lemma_}\\t\\t{token.pos_}\\t\\t{token.tag_}\\t\\t{token.dep_}\\t\\t{token.shape_}\\t\\t{token.is_alpha}\\t\\t{token.is_stop}\")\n",
        "\n",
        "# Named Entity Recognition\n",
        "print(\"\\nNamed Entities:\")\n",
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token\t\tLemma\t\tPOS\t\tTag\t\tDep\t\tShape\t\tis_alpha\tis_stop\n",
            "Apple\t\tApple\t\tPROPN\t\tNNP\t\tnsubj\t\tXxxxx\t\tTrue\t\tFalse\n",
            "is\t\tbe\t\tAUX\t\tVBZ\t\taux\t\txx\t\tTrue\t\tTrue\n",
            "looking\t\tlook\t\tVERB\t\tVBG\t\tROOT\t\txxxx\t\tTrue\t\tFalse\n",
            "at\t\tat\t\tADP\t\tIN\t\tprep\t\txx\t\tTrue\t\tTrue\n",
            "buying\t\tbuy\t\tVERB\t\tVBG\t\tpcomp\t\txxxx\t\tTrue\t\tFalse\n",
            "U.K.\t\tU.K.\t\tPROPN\t\tNNP\t\tdobj\t\tX.X.\t\tFalse\t\tFalse\n",
            "startup\t\tstartup\t\tNOUN\t\tNN\t\tdep\t\txxxx\t\tTrue\t\tFalse\n",
            "for\t\tfor\t\tADP\t\tIN\t\tprep\t\txxx\t\tTrue\t\tTrue\n",
            "$\t\t$\t\tSYM\t\t$\t\tquantmod\t\t$\t\tFalse\t\tFalse\n",
            "1\t\t1\t\tNUM\t\tCD\t\tcompound\t\td\t\tFalse\t\tFalse\n",
            "billion\t\tbillion\t\tNUM\t\tCD\t\tpobj\t\txxxx\t\tTrue\t\tFalse\n",
            "\n",
            "Named Entities:\n",
            "Apple 0 5 ORG\n",
            "U.K. 27 31 GPE\n",
            "$1 billion 44 54 MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. Loading a Language Model:\n",
        "\n",
        "> The en_core_web_sm model is a small English model. You can load it as follows:\n",
        "\n"
      ],
      "metadata": {
        "id": "d1YM4hYxycQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "q4cI5mcGyhpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. Processing Text:\n",
        "> With the model loaded, you can process text documents. This step allows you to perform various NLP tasks on the text."
      ],
      "metadata": {
        "id": "utSyPrmlyumP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(\"Apple is looking at buying U.K. startup for $1 billion\")"
      ],
      "metadata": {
        "id": "1lBxlkfoyyDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. Tokenization:\n",
        ">This breaks up the text into individual words or tokens."
      ],
      "metadata": {
        "id": "oa9LIihbyzsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-P58dQby0H-",
        "outputId": "114dd1a3-f95a-45ca-89e0-f9feba5849d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple\n",
            "is\n",
            "looking\n",
            "at\n",
            "buying\n",
            "U.K.\n",
            "startup\n",
            "for\n",
            "$\n",
            "1\n",
            "billion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. Part-of-Speech Tagging:\n",
        ">spaCy can also annotate tokens with their part of speech."
      ],
      "metadata": {
        "id": "4Lno_XNuyzm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:<{10}}, {token.pos_:>{10}}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JlSgszqQy0hJ",
        "outputId": "143bf7c5-fda1-4fe1-91ea-cf5ff5d00939"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple     ,      PROPN\n",
            "is        ,        AUX\n",
            "looking   ,       VERB\n",
            "at        ,        ADP\n",
            "buying    ,       VERB\n",
            "U.K.      ,      PROPN\n",
            "startup   ,       NOUN\n",
            "for       ,        ADP\n",
            "$         ,        SYM\n",
            "1         ,        NUM\n",
            "billion   ,        NUM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. Named Entity Recognition (NER):\n",
        ">spaCy can recognize various entities in the text, such as companies or locations."
      ],
      "metadata": {
        "id": "2ryMFCGmzAgr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "    print(f'{ent.text:<{10}}, {ent.label_:>{10}}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2up-RYlVzZOX",
        "outputId": "0dc33179-769a-42d0-b1f2-0f3d8a7d5086"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple     ,        ORG\n",
            "U.K.      ,        GPE\n",
            "$1 billion,      MONEY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. Dependency Parsing:\n",
        ">You can analyze the grammatical structure of sentences."
      ],
      "metadata": {
        "id": "QBUWixkuzq-B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:<{10}}, {token.dep_:<{10}}, {token.head.text:>{10}}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CapxVIm2zaEK",
        "outputId": "8224518b-12d0-42bc-d1d8-9b031c3d83c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple     , nsubj     ,    looking\n",
            "is        , aux       ,    looking\n",
            "looking   , ROOT      ,    looking\n",
            "at        , prep      ,    looking\n",
            "buying    , pcomp     ,         at\n",
            "U.K.      , dobj      ,     buying\n",
            "startup   , dep       ,    looking\n",
            "for       , prep      ,    startup\n",
            "$         , quantmod  ,    billion\n",
            "1         , compound  ,    billion\n",
            "billion   , pobj      ,        for\n"
          ]
        }
      ]
    }
  ]
}